{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee311443-6c31-4f69-a423-39385c483e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5bde12-96d4-4c58-919f-a3cdd685fc77",
   "metadata": {},
   "source": [
    "## Causative alternation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b90087e6-926c-4443-adce-58ce45c185a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs = [\"caramelized\", \"fermented\", \"roasted\", \"toasted\", \"simmered\"]\n",
    "objects = [\"onions\", \"tomatoes\", \"potatoes\", \"meat\"]\n",
    "\n",
    "# Create 20 sentences with transitive verbs\n",
    "transitive = [f'The chef {verb} the {obj}.' for obj in objects for verb in verbs]\n",
    "\n",
    "# Change the 20 sentences above by causative alternation\n",
    "intransitive = [f'The {obj} {verb} last night.' for obj in objects for verb in verbs]\n",
    "counting = [f'{obj}' for obj in objects for verb in verbs]\n",
    "\n",
    "# Save key information of each pair of sentence\n",
    "data = []\n",
    "for i, sent in enumerate(transitive):\n",
    "    example = {'capability': \"causative_alternation\",\n",
    "               'test_type': \"MFT\",\n",
    "               'test_case': (sent, intransitive[i]),\n",
    "               'target': (counting[i], counting[i]),\n",
    "               'expected_label': \"ARG1\"}\n",
    "    data.append(example)\n",
    "\n",
    "# Save as JSON file for the MFT test\n",
    "causative_alternation = {}\n",
    "causative_alternation['data'] = data\n",
    "with open(\"data/causative_alternation.json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(causative_alternation, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b88654d-89c1-4301-916f-90b1d195f381",
   "metadata": {},
   "source": [
    "## Long Distance Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "584487e0-a7c3-4b9a-8ae2-ec77093e2ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_clauses = [\"whose voice was like honey\",\n",
    "                    \"who had just won a Grammy\",\n",
    "                    \"who had traveled from another country\",\n",
    "                    \"who was known for his improvisation skills\",\n",
    "                    \"who had played with many famous musicians\",\n",
    "                    \"who had just released a new album\",\n",
    "                    \"who had studied music at Juilliard\",\n",
    "                    \"who was known for his stage presence\",\n",
    "                    \"whose music had inspired a generation\",\n",
    "                    \"who had a loyal fan base\"]\n",
    "\n",
    "# Create original sentences\n",
    "original_sentence = ['The musician tapped the drum with a drumstick.']*10\n",
    "\n",
    "# Create sentences with embedded clauses\n",
    "sentence_with_clause = [f'The musician {clause} tapped the drum with a drumstick.' for clause in embedded_clauses]\n",
    "\n",
    "# Save key information of each pair of sentence\n",
    "data = []\n",
    "for i, sent in enumerate(original_sentence):\n",
    "    example = {'capability': \"long_distance_dependencies\",\n",
    "               'test_type': \"INV\",\n",
    "               'test_case': (sent, sentence_with_clause[i]),\n",
    "               'target': (\"drumstick\", \"drumstick\"),\n",
    "               'expected_label': \"ARG2\"}\n",
    "    data.append(example)\n",
    "\n",
    "# Save as JSON file for the INV test\n",
    "long_distance_dependencies = {}\n",
    "long_distance_dependencies['data'] = data\n",
    "with open(\"data/long_distance_dependencies.json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(long_distance_dependencies, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f315580f-a25b-4f1c-a5b9-017c6d36da9f",
   "metadata": {},
   "source": [
    "## Location modifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97221a17-b02c-4ade-a453-62043748b93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = ['Amsterdam', 'New York', 'London', 'Paris', 'Tokyo', \n",
    "             'Sydney', 'Dubai', 'Hong Kong', 'Mumbai', 'Singapore']\n",
    "\n",
    "occupations = ['finance', 'marketing', 'healthcare', 'education', 'retail',\n",
    "               'government', 'advertising', 'manufacturing', 'consulting', 'real estate']\n",
    "\n",
    "# Create 10 sentences with ARGM-LOC\n",
    "argm_loc = [f'He works in {location}.' for location in locations]\n",
    "\n",
    "# Change the 10 sentences above with ARG2\n",
    "arg_2 = [f'He works in {occupation}.' for occupation in occupations]\n",
    "\n",
    "# Save key information of each pair of sentence\n",
    "data = []\n",
    "for i, sent in enumerate(argm_loc):\n",
    "    example = {'capability': \"location_modifiers\",\n",
    "               'test_type': \"DIR\",\n",
    "               'test_case': (sent, arg_2[i]),\n",
    "               'target': (locations[i], occupations[i]),\n",
    "               'expected_label': (\"ARGM-LOC\", \"ARG2\")}\n",
    "    data.append(example)\n",
    "\n",
    "# Save as JSON file for the DIR test\n",
    "location_modifiers = {}\n",
    "location_modifiers['data'] = data\n",
    "with open(\"data/location_modifiers.json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(location_modifiers, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1497cd2d-61db-4b4d-a662-7b909f9310bc",
   "metadata": {},
   "source": [
    "## Voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6eeb0e6-5d01-4636-9014-77989ebe0e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = ['Alice', 'Bob']\n",
    "verbs = [\"burned\", \"dropped\", \"opened\", \"closed\", \"found\", \"kicked\", \"painted\", \"moved\", \"flipped\", \"picked\"]\n",
    "\n",
    "# Create 50 active sentences\n",
    "active_sentence = [f'{subject} {verb} the box.' for subject in subjects for verb in verbs]\n",
    "\n",
    "# Change the 50 sentences above as passive sentences\n",
    "passive_sentence = [f'The box was {verb} by {subject}.' for subject in subjects for verb in verbs]\n",
    "\n",
    "# Save key information of each pair of sentence\n",
    "data = []\n",
    "for i, sent in enumerate(active_sentence):\n",
    "    example = {'capability': \"voice\",\n",
    "               'test_type': \"MFT\",\n",
    "               'test_case': (sent, passive_sentence[i]),\n",
    "               'target': (\"box\", \"box\"),\n",
    "               'expected_label': \"ARG1\"}\n",
    "    data.append(example)\n",
    "\n",
    "# Save as JSON file for the MFT test\n",
    "voice = {}\n",
    "voice['data'] = data\n",
    "with open(\"data/voice.json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(voice, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beadea42-7bd7-481b-9d73-035be58205f6",
   "metadata": {},
   "source": [
    "## Robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a0599b3-e624-481e-bfa8-f3dfe1104ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Boy = [\"boi\", \"boyz\", \"bly\", \"bey\", \"boy\"]\n",
    "Played = [\"pleyed\", \"playd\", \"plaied\", \"plyed\"]\n",
    "Friends = [\"frends\", \"freinds\", \"frinds\", \"frands\", \"friends\"]\n",
    "\n",
    "# Create original sentences\n",
    "sentence = ['The boy played with his friends.']*100\n",
    "\n",
    "# Replace some words in the original sentences with some typos or misspellings\n",
    "typos = [f'The {boy} {played} with his {friends}.' for boy in Boy for played in Played for friends in Friends]\n",
    "counting = [f'{boy}' for boy in Boy for played in Played for friends in Friends]\n",
    "\n",
    "# Save key information of each pair of sentence\n",
    "data = []\n",
    "for i, sent in enumerate(sentence):\n",
    "    example = {'capability': \"robustness\",\n",
    "               'test_type': \"INV\",\n",
    "               'test_case': (sent, typos[i]),\n",
    "               'target': (\"boy\", counting[i]),\n",
    "               'expected_label': \"ARG0\"}\n",
    "    data.append(example)\n",
    "\n",
    "# Save as JSON file for the INV test\n",
    "robustness = {}\n",
    "robustness['data'] = data\n",
    "with open(\"data/robustness.json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(robustness, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hlt_env",
   "language": "python",
   "name": "hlt_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
